{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN\n",
    "Train on the Masks dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import skimage.draw\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "sys.path.append(ROOT_DIR) \n",
    "from mrcnn.config import Config\n",
    "from mrcnn import model as modellib, utils, visualize\n",
    "\n",
    "COCO_WEIGHTS_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\n",
    "DEFAULT_LOGS_DIR = os.path.join(ROOT_DIR, \"logs\")\n",
    "NUM_EPOCHS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        100\n",
      "DETECTION_MIN_CONFIDENCE       0.9\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  512\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [512 512   3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0, 'rpn_class_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           mask_cfg\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                100\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class MaskConfig(Config):\n",
    "    \"\"\"Configuration for training on the dataset.\n",
    "    Derives from the base Config class and overrides some values.\n",
    "    \"\"\"\n",
    "    NAME = \"mask_cfg\"\n",
    "    IMAGES_PER_GPU = 1\n",
    "    NUM_CLASSES = 1 + 1  # Background + mask\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    DETECTION_MIN_CONFIDENCE = 0.9\n",
    "    IMAGE_MAX_DIM = 512\n",
    "    LEARNING_RATE = 0.001\n",
    "    \n",
    "config = MaskConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskDataset(utils.Dataset):\n",
    "    \"\"\"Dataset for mask detection. Inherits from utils.Dataset.\"\"\"\n",
    "\n",
    "    def load_data(self, filenames_split, annotations, subset):\n",
    "        \"\"\"Load the dataset from JSON annotations and split filenames.\"\"\"\n",
    "        \n",
    "        dataset_dir = os.path.join(os.getcwd(), 'dataset')\n",
    "        self.add_class('mask', 1, 'mask')\n",
    "\n",
    "        if subset == 'train':\n",
    "            selected_filenames = filenames_split['train']\n",
    "        elif subset == 'val':\n",
    "            selected_filenames = filenames_split['val']\n",
    "        else:\n",
    "            selected_filenames = filenames_split['test']\n",
    "\n",
    "        for filename in selected_filenames:\n",
    "            image_info = annotations[filename]\n",
    "            image_path = os.path.join(dataset_dir, image_info['filename'])\n",
    "            polygons = image_info['regions']\n",
    "            boxes = []\n",
    "\n",
    "            for region in polygons:\n",
    "                shape = region['shape_attributes']\n",
    "                if shape['name'] == 'rect':\n",
    "                    x = shape['x']\n",
    "                    y = shape['y']\n",
    "                    width_box = shape['width']\n",
    "                    height_box = shape['height']\n",
    "                    boxes.append([x, y, x + width_box, y + height_box])\n",
    "\n",
    "                self.add_image(\n",
    "                    \"mask\", image_id=filename, path=image_path,\n",
    "                    width=config.IMAGE_SHAPE[0], height=config.IMAGE_SHAPE[1], boxes=boxes)\n",
    "\n",
    "    def load_image(self, image_id):\n",
    "        \"\"\"Load the image corresponding to the given image_id.\"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        image = skimage.io.imread(info['path'])\n",
    "\n",
    "        # Remove alpha channel if present\n",
    "        if image.shape[-1] == 4:\n",
    "            image = image[..., :3]\n",
    "        \n",
    "        return image\n",
    "\n",
    "    def load_mask(self, image_id):\n",
    "        \"\"\"Generate instance masks for an image.\n",
    "        Returns:\n",
    "        masks: A bool array of shape [height, width, instance count] with one mask per instance.\n",
    "        class_ids: a 1D array of class IDs of the instance masks.\n",
    "        \"\"\"\n",
    "        info = self.image_info[image_id]\n",
    "        boxes = info['boxes']\n",
    "\n",
    "        # Create an empty mask for each bounding box\n",
    "        mask = np.zeros([info['height'], info['width'], len(boxes)], dtype=np.uint8)\n",
    "\n",
    "        for i, box in enumerate(boxes):\n",
    "            x1, y1, x2, y2 = box\n",
    "            mask[y1:y2, x1:x2, i] = 1\n",
    "\n",
    "        return mask.astype(np.bool_), np.ones([mask.shape[-1]], dtype=np.int32)\n",
    "\n",
    "    def image_reference(self, image_id):\n",
    "        \"\"\"Return the image path reference.\"\"\"\n",
    "        return self.image_info[image_id]['path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and split images\n",
    "dataset_dir = os.path.join(os.getcwd(), 'dataset')\n",
    "json_file = os.path.join(dataset_dir, \"annotations.json\")\n",
    "\n",
    "with open(json_file) as json_file:\n",
    "    annotations = json.load(json_file)\n",
    "\n",
    "filenames = list(annotations.keys())\n",
    "\n",
    "train_filenames, other = train_test_split(filenames, test_size=0.7, random_state=42)\n",
    "val_filenames, test_filenames = train_test_split(other, test_size=0.5, random_state=42)\n",
    "filenames_split = {'train': train_filenames, 'val': val_filenames, 'test': test_filenames}\n",
    "\n",
    "# Training dataset\n",
    "dataset_train = MaskDataset()\n",
    "dataset_train.load_data(filenames_split, annotations, 'train')\n",
    "dataset_train.prepare()\n",
    "\n",
    "# Validation dataset\n",
    "dataset_val = MaskDataset()\n",
    "dataset_val.load_data(filenames_split, annotations, 'val')\n",
    "dataset_val.prepare()\n",
    "\n",
    "# Test dataset\n",
    "dataset_test = MaskDataset()\n",
    "dataset_test.load_data(filenames_split, annotations, 'test')\n",
    "dataset_test.prepare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to load the **COCO** model and split the images into training, validation and train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = modellib.MaskRCNN(mode=\"training\", config=config, model_dir=DEFAULT_LOGS_DIR)\n",
    "model.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n",
    "            \"mrcnn_class_logits\", \"mrcnn_bbox_fc\",\n",
    "            \"mrcnn_bbox\", \"mrcnn_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting at epoch 0. LR=0.001\n",
      "\n",
      "Checkpoint Path: /tmp/mrcnn/logs/mask_cfg20241125T1730/mask_rcnn_mask_cfg_{epoch:04d}.h5\n",
      "Selecting layers to train\n",
      "fpn_c5p5               (Conv2D)\n",
      "fpn_c4p4               (Conv2D)\n",
      "fpn_c3p3               (Conv2D)\n",
      "fpn_c2p2               (Conv2D)\n",
      "fpn_p5                 (Conv2D)\n",
      "fpn_p2                 (Conv2D)\n",
      "fpn_p3                 (Conv2D)\n",
      "fpn_p4                 (Conv2D)\n",
      "In model:  rpn_model\n",
      "    rpn_conv_shared        (Conv2D)\n",
      "    rpn_class_raw          (Conv2D)\n",
      "    rpn_bbox_pred          (Conv2D)\n",
      "mrcnn_mask_conv1       (TimeDistributed)\n",
      "mrcnn_mask_bn1         (TimeDistributed)\n",
      "mrcnn_mask_conv2       (TimeDistributed)\n",
      "mrcnn_mask_bn2         (TimeDistributed)\n",
      "mrcnn_class_conv1      (TimeDistributed)\n",
      "mrcnn_class_bn1        (TimeDistributed)\n",
      "mrcnn_mask_conv3       (TimeDistributed)\n",
      "mrcnn_mask_bn3         (TimeDistributed)\n",
      "mrcnn_class_conv2      (TimeDistributed)\n",
      "mrcnn_class_bn2        (TimeDistributed)\n",
      "mrcnn_mask_conv4       (TimeDistributed)\n",
      "mrcnn_mask_bn4         (TimeDistributed)\n",
      "mrcnn_bbox_fc          (TimeDistributed)\n",
      "mrcnn_mask_deconv      (TimeDistributed)\n",
      "mrcnn_class_logits     (TimeDistributed)\n",
      "mrcnn_mask             (TimeDistributed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:98: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:2087: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 99/100 [============================>.] - ETA: 14s - loss: 2.1457 - rpn_class_loss: 0.1648 - rpn_bbox_loss: 0.7812 - mrcnn_class_loss: 0.2268 - mrcnn_bbox_loss: 0.5712 - mrcnn_mask_loss: 0.4017"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/training.py:2330: UserWarning: Using a generator with `use_multiprocessing=True` and multiple workers may duplicate your data. Please consider using the`keras.utils.Sequence class.\n",
      "  UserWarning('Using a generator with `use_multiprocessing=True`'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1479s 15s/step - loss: 2.1393 - rpn_class_loss: 0.1647 - rpn_bbox_loss: 0.7786 - mrcnn_class_loss: 0.2252 - mrcnn_bbox_loss: 0.5689 - mrcnn_mask_loss: 0.4018 - val_loss: 1.8146 - val_rpn_class_loss: 0.1086 - val_rpn_bbox_loss: 0.6214 - val_mrcnn_class_loss: 0.1911 - val_mrcnn_bbox_loss: 0.5222 - val_mrcnn_mask_loss: 0.3712\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 1472s 15s/step - loss: 1.4704 - rpn_class_loss: 0.1237 - rpn_bbox_loss: 0.4944 - mrcnn_class_loss: 0.1962 - mrcnn_bbox_loss: 0.3133 - mrcnn_mask_loss: 0.3429 - val_loss: 1.5238 - val_rpn_class_loss: 0.0953 - val_rpn_bbox_loss: 0.4598 - val_mrcnn_class_loss: 0.1378 - val_mrcnn_bbox_loss: 0.5019 - val_mrcnn_mask_loss: 0.3289\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 1472s 15s/step - loss: 1.2681 - rpn_class_loss: 0.0952 - rpn_bbox_loss: 0.4228 - mrcnn_class_loss: 0.1316 - mrcnn_bbox_loss: 0.3069 - mrcnn_mask_loss: 0.3117 - val_loss: 1.3899 - val_rpn_class_loss: 0.0781 - val_rpn_bbox_loss: 0.4012 - val_mrcnn_class_loss: 0.1933 - val_mrcnn_bbox_loss: 0.3772 - val_mrcnn_mask_loss: 0.3401\n"
     ]
    }
   ],
   "source": [
    "model.train(dataset_train, dataset_val,\n",
    "                learning_rate=config.LEARNING_RATE,\n",
    "                epochs=NUM_EPOCHS,\n",
    "                layers='heads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_iou(box1, box2):\n",
    "  x1 = max(box1[0], box2[0])\n",
    "  y1 = max(box1[1], box2[1])\n",
    "  x2 = min(box1[2], box2[2])\n",
    "  y2 = min(box1[3], box2[3])\n",
    "\n",
    "  intersection = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n",
    "  box1_area = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1)\n",
    "  box2_area = (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1)\n",
    "  union = box1_area + box2_area - intersection\n",
    "\n",
    "  return intersection / union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'B:\\Mask-RCNN-TF2\\custom\\logs\\v1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-80d095442f16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodellib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskRCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"inference\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDEFAULT_LOGS_DIR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr\"B:\\Mask-RCNN-TF2\\custom\\logs\\v1.h5\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mby_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/mask_rcnn-2.1-py3.5.egg/mrcnn/model.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, exclude)\u001b[0m\n\u001b[1;32m   2113\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2114\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`load_weights` requires h5py.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2115\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2116\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2117\u001b[0m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m                 \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'B:\\Mask-RCNN-TF2\\custom\\logs\\v1.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mrcnn.model as modellib\n",
    "\n",
    "model = modellib.MaskRCNN(mode=\"inference\", config=config, model_dir=DEFAULT_LOGS_DIR)\n",
    "model_path = r\"./logs/v1.h5\"\n",
    "model.load_weights(model_path, by_name=True)\n",
    "\n",
    "y_true, y_pred = {}, {}\n",
    "\n",
    "for image_id in dataset_test.image_ids:\n",
    "    \n",
    "    image, image_meta, gt_class_id, gt_box, gt_mask = modellib.load_image_gt(\n",
    "        dataset_test, config, image_id, use_mini_mask=False\n",
    "    )\n",
    "\n",
    "    results = model.detect([image], verbose=0)\n",
    "    \n",
    "    # pour chaque image : liste des bbox et liste des pred\n",
    "    y_true[image_id] = gt_box\n",
    "    y_pred[image_id] = results[0]['rois']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_detections(y_pred, y_true, iou_threshold=0.5):\n",
    "\n",
    "  tp = 0\n",
    "  fp = 0\n",
    "  fn = 0\n",
    "\n",
    "  matched_gt = set()\n",
    "\n",
    "  for pred_box in y_pred:\n",
    "    matched = False\n",
    "    for gt_index, gt_box in enumerate(y_true):\n",
    "      if gt_index in matched_gt:\n",
    "        continue\n",
    "      iou = compute_iou(pred_box, gt_box)\n",
    "      if iou >= iou_threshold:\n",
    "        tp += 1\n",
    "        matched_gt.add(gt_index)\n",
    "        matched = True\n",
    "        break\n",
    "    if not matched:\n",
    "      fp += 1\n",
    "\n",
    "  fn = len(y_true) - len(matched_gt)\n",
    "\n",
    "  return tp, fp, fn\n",
    "\n",
    "total_tp = 0\n",
    "total_fp = 0\n",
    "total_fn = 0\n",
    "\n",
    "for image_id in dataset_test.image_ids:\n",
    "    tp, fp, fn = evaluate_detections(y_pred[image_id], y_true[image_id])\n",
    "    total_tp += tp\n",
    "    total_fp += fp\n",
    "    total_fn += fn\n",
    "    \n",
    "total_tp, total_fp, total_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "cm = np.array([[total_tp, total_fn], [total_fp, 0]])\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index=[\"Masques\", \"Background\"], columns=[\"Masques\", \"Background\"])\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(df_cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "\n",
    "plt.savefig('confusion_matrix.png', bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
